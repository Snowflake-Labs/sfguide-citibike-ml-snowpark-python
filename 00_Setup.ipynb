{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup or Reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning!!!!\n",
    "### Running this code will delete an existing database as specified in the state dictionary below.\n",
    "\n",
    "We need a way to save state throughout the project.  We will initially login as the ACCOUNTADMIN role in order to setup some additional users as well as the compute resources we will need. \n",
    "\n",
    "We will specify a couple of different compute resources which allows us to scale up and down easily.  Most of the workflow can use an extra-small warehouse but for certain tasks (ie. feature engineering and model training) we may need larger compute.  By specifying them in the state dictionary we can easily select the correct compute for any particular task.\n",
    "  \n",
    "Update the \\<USERNAME>, \\<ACCOUNTNAME>, \\<DOMAIN> in the state dictionary below with the initial user that was created with your trial account.\n",
    "\n",
    "Note: If you are running the US West (Oregon) region, you don't need to add the \\<DOMAIN>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {\n",
    "    \"connection_parameters\": {\"user\": \"FLETCHJEFF\",\n",
    "                              \"account\": \"WLA07438\",\n",
    "                              \"role\": \"ACCOUNTADMIN\"\n",
    "                             },\n",
    "    \"compute_parameters\" : {\"default_warehouse\": \"XSMALL_WH\",  \n",
    "                            \"task_warehouse\": \"XSMALL_WH\",  \n",
    "                            \"load_warehouse\": \"LARGE_WH\",  \n",
    "                            \"fe_warehouse\": \"XXLARGE_WH\",  \n",
    "                            \"train_warehouse\": \"XXLARGE_WH\"  \n",
    "                            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./include/state.json', 'w') as sdf:\n",
    "    json.dump(state_dict, sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will connect with username and password.  In a non-demo system it is very important to use properly secured passwords with secret managers and/or oauth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter password for user with ACCOUNTADMIN role access ···············\n"
     ]
    }
   ],
   "source": [
    "import snowflake.snowpark as snp\n",
    "import json\n",
    "import getpass\n",
    "\n",
    "account_admin_password = getpass.getpass('Enter password for user with ACCOUNTADMIN role access')\n",
    "\n",
    "with open('./include/state.json') as sdf:\n",
    "    state_dict = json.load(sdf)\n",
    "state_dict['connection_parameters']['password'] = account_admin_password\n",
    "\n",
    "session = snp.Session.builder.configs(state_dict[\"connection_parameters\"]).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use a specific AWS S3 role for accessing pre-staged files to speed up the hands-on-lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict['connection_parameters']['download_base_url'] = 's3://sfquickstarts/vhol_citibike_ml_snowpark_python/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather data has a different prefix, depending on the the region used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"show shares like '%SNOWPARK%'\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1897/3440518646.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweather_listing_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"show shares like '%SNOWPARK%'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weather_listing_prefix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweather_listing_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/snowpark_070/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weather_listing_prefix = pd.DataFrame(session.sql(\"show shares like '%SNOWPARK%'\").collect()).name[0].split('.')[0]\n",
    "state_dict['weather_listing_prefix'] = weather_listing_prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this without access to pre-staged files run the following cell instead of the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict['connection_parameters']['download_base_url'] = 'https://s3.amazonaws.com/tripdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sample user which will be used for the hands-on-lab.  Normally you will have different roles (and possibly different users) for data scientists, data engineers, ML engineers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.use_role('securityadmin')\n",
    "\n",
    "demo_username='jack'\n",
    "project_role='PUBLIC'\n",
    "\n",
    "session.sql(\"CREATE USER IF NOT EXISTS \"+demo_username+\\\n",
    "            \" LOGIN_NAME = '\"+demo_username+\"'\"+\\\n",
    "            \" FIRST_NAME = 'SNOWPARK'\"+\\\n",
    "            \" LAST_NAME = 'HOL'\"+\\\n",
    "            \" EMAIL = 'john@hol.snowpark'\"+\\\n",
    "            \" DEFAULT_ROLE = '\"+project_role+\"'\"+\\\n",
    "            \" MUST_CHANGE_PASSWORD = FALSE\")\\\n",
    "        .collect()\n",
    "\n",
    "session.sql(\"GRANT ROLE \"+project_role+\" TO USER \"+demo_username).collect()\n",
    "\n",
    "session.use_role('sysadmin')\n",
    "session.sql(\"GRANT CREATE DATABASE ON ACCOUNT TO ROLE \"+project_role).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a new password for the demo user jack ···············\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.use_role('securityadmin')\n",
    "demo_user_password=getpass.getpass('Enter a new password for the demo user '+demo_username)\n",
    "session.sql(\"ALTER USER \"+demo_username+\" SET PASSWORD = '\"+demo_user_password+\"'\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create compute instances as specified in the state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.use_role('ACCOUNTADMIN')\n",
    "project_role='PUBLIC'\n",
    "\n",
    "for wh in state_dict['compute_parameters'].values():\n",
    "    session.sql(\"CREATE WAREHOUSE IF NOT EXISTS \"+wh+\\\n",
    "            \" WITH WAREHOUSE_SIZE = '\"+wh.split('_')[0]+\\\n",
    "            \"' WAREHOUSE_TYPE = 'STANDARD' AUTO_SUSPEND = 60 AUTO_RESUME = TRUE initially_suspended = true;\")\\\n",
    "        .collect()\n",
    "    session.sql(\"GRANT USAGE ON WAREHOUSE \"+wh+\" TO ROLE \"+project_role).collect() \n",
    "    session.sql(\"GRANT OPERATE ON WAREHOUSE \"+wh+\" TO ROLE \"+project_role).collect() \n",
    "    \n",
    "session.use_role(state_dict['connection_parameters']['role'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow users to import data shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Statement executed successfully.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.use_role('ACCOUNTADMIN')\n",
    "session.sql(\"GRANT IMPORT SHARE ON ACCOUNT TO \"+project_role).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now update the state dictionary to use the non-admin account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict['connection_parameters']['user'] = demo_username\n",
    "state_dict['connection_parameters']['password'] = demo_user_password\n",
    "state_dict['connection_parameters']['role'] = project_role\n",
    "state_dict['connection_parameters']['database'] = 'CITIBIKEML_'+demo_username\n",
    "state_dict['connection_parameters']['schema'] = 'DEMO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the updated state dictionary for project team use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./include/state.json', 'w') as sdf:\n",
    "    json.dump(state_dict, sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a python function to simplify the users' steps of starting a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dags/snowpark_connection.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dags/snowpark_connection.py\n",
    "def snowpark_connect(state_file='./include/state.json'):\n",
    "    import snowflake.snowpark as snp\n",
    "    import json\n",
    "    \n",
    "    with open(state_file) as sdf:\n",
    "        state_dict = json.load(sdf)    \n",
    "    \n",
    "    session=None\n",
    "    session = snp.Session.builder.configs(state_dict[\"connection_parameters\"]).create()\n",
    "    session.use_warehouse(state_dict['compute_parameters']['default_warehouse'])\n",
    "    return session, state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function that users will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dags.snowpark_connection import snowpark_connect\n",
    "session, state_dict = snowpark_connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the user has access to each compute instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"XSMALL_WH\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_current_warehouse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wh in state_dict['compute_parameters'].keys():\n",
    "    session.use_warehouse(state_dict['compute_parameters'][wh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"XXLARGE_WH\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_current_warehouse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the database and schema for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "cforbe"
   }
  ],
  "kernelspec": {
   "display_name": "snowpark_070:Python",
   "language": "python",
   "name": "conda-env-snowpark_070-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "msauthor": "trbye"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
